{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PM2 — Task F: Sparsity & Reordering\n",
    "Team: Camille Wardlaw, Manuel Valencia, Demircan Tas\\\n",
    "Scope: Task F (Sparsity Analysis and Matrix Reordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os, math, warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import svds, spsolve\n",
    "from numpy.linalg import cond as dense_cond\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "np.random.seed(0)\n",
    "plt.rcParams.update({'figure.figsize': (7.5,4.5), 'axes.grid': True})\n",
    "os.makedirs('temp/pm2', exist_ok=True)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project imports\n",
    "from getParam_Sonar import getParam_Sonar\n",
    "from eval_f_Sonar import eval_f_Sonar\n",
    "from eval_Jf_Sonar import eval_Jf_Sonar\n",
    "from eval_Jf_FiniteDifference import eval_Jf_FiniteDifference\n",
    "from eval_g_Sonar import eval_g_Sonar\n",
    "from eval_u_Sonar import eval_u_Sonar\n",
    "from simpleLeapFrog import LeapfrogSolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Task F - Sparsity & Reordering\n",
    "\n",
    "### a) How sparse are the matrices? Visualized the matrix with the sparsity and estimate the computational complexity for factoring it \"as is\" as well estimating an upper bound for the possible fill-ins that may occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csr(M):\n",
    "    \"\"\"Return CSR sparse matrix without copying big dense inputs unless needed.\"\"\"\n",
    "    if sp.issparse(M):\n",
    "        return M.tocsr()\n",
    "    M = np.asarray(M)\n",
    "    return sp.csr_matrix(M)\n",
    "\n",
    "def half_bandwidth(M):\n",
    "    \"\"\"\n",
    "    Compute half-bandwidth β = max_{(i,j) in nz} |i - j| using the symmetric pattern.\n",
    "    \"\"\"\n",
    "    M = to_csr(M)\n",
    "    # symmetric pattern\n",
    "    S = (M != 0).astype(np.int8)\n",
    "    S = (S + S.T).astype(np.int8)\n",
    "    S = S.tocoo()\n",
    "    if S.nnz == 0:\n",
    "        return 0\n",
    "    return int(np.max(np.abs(S.row - S.col)))\n",
    "\n",
    "def sparsity_stats(M, name=\"A\", show=True, markersize=0.01, symmetrize=False):\n",
    "    \"\"\"\n",
    "    Print sparsity, envelopes, and skyline profile for M.\n",
    "\n",
    "    Envelopes are computed on the *symmetrized* pattern S = nz(M) ∪ nz(Mᵀ)\n",
    "    (set symmetrize=False to use M's original pattern).\n",
    "\n",
    "    For each row i with nonzeros in S:\n",
    "      j_min(i) = leftmost column index\n",
    "      j_max(i) = rightmost column index\n",
    "\n",
    "    Lower envelope  ρ_L = Σ_i max(0, i - j_min(i))\n",
    "    Upper envelope  ρ_U = Σ_i max(0, j_max(i) - i)\n",
    "    Total profile   ρ   = ρ_L + ρ_U + n         (includes diagonal)\n",
    "    Half-bandwidth  β   = max_i max(i - j_min(i), j_max(i) - i)\n",
    "\n",
    "    Returns a dict with these quantities.\n",
    "    \"\"\"\n",
    "    M = to_csr(M)\n",
    "    n = M.shape[0]\n",
    "\n",
    "    # Choose pattern to analyze\n",
    "    P = (M != 0).astype(np.int8)\n",
    "    if symmetrize:\n",
    "        P = (P + P.T).astype(np.int8)\n",
    "    P = P.tocsr()\n",
    "\n",
    "    # Basic counts on the original matrix M (not the symmetrized pattern)\n",
    "    nnz = M.nnz\n",
    "    density = nnz / (n * n)\n",
    "\n",
    "    # Row-wise envelopes\n",
    "    indptr, indices = P.indptr, P.indices\n",
    "    rho_L = 0  # lower (to the left of diag)\n",
    "    rho_U = 0  # upper (to the right of diag)\n",
    "    beta  = 0  # half-bandwidth\n",
    "\n",
    "    for i in range(n):\n",
    "        start, end = indptr[i], indptr[i+1]\n",
    "        if end == start:\n",
    "            continue  # empty row in pattern\n",
    "        jmin = indices[start]\n",
    "        jmax = indices[end - 1]\n",
    "        # ensure monotone (CSR indices are sorted by row)\n",
    "        dl = max(0, i - jmin)   # distance to leftmost nz\n",
    "        du = max(0, jmax - i)   # distance to rightmost nz\n",
    "        rho_L += dl\n",
    "        rho_U += du\n",
    "        if dl > beta: beta = dl\n",
    "        if du > beta: beta = du\n",
    "\n",
    "    rho_total = rho_L + rho_U + n  # include diagonal\n",
    "\n",
    "    # Print report\n",
    "    print(f\"[{name}] n={n:,}, nnz(M)={nnz:,}, density={density:.3e}\")\n",
    "    print(f\"    envelopes on {'symmetrized' if symmetrize else 'original'} pattern:\")\n",
    "    print(f\"    lower envelope  ρ_L = {rho_L:,}\")\n",
    "    print(f\"    upper envelope  ρ_U = {rho_U:,}\")\n",
    "    print(f\"    total profile   ρ   = {rho_total:,}\")\n",
    "    print(f\"    half-bandwidth  β   = {beta:,}\")\n",
    "\n",
    "    # Visualize sparsity of the original M\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.spy(M, markersize=markersize)\n",
    "        ax.set_title(f\"{name} sparsity (nnz={nnz:,}, dens={density:.2e})\")\n",
    "        ax.set_xlabel(\"column\")\n",
    "        ax.set_ylabel(\"row\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"n\": n,\n",
    "        \"nnz\": nnz,\n",
    "        \"density\": density,\n",
    "        \"lower_envelope\": int(rho_L),\n",
    "        \"upper_envelope\": int(rho_U),\n",
    "        \"profile_total\": int(rho_total),\n",
    "        \"beta\": int(beta),\n",
    "        \"symmetrized\": bool(symmetrize),\n",
    "    }\n",
    "\n",
    "def lu_band_cost_upper_bounds(n, beta):\n",
    "    \"\"\"\n",
    "    Common back-of-envelope bounds for banded LU *without pivoting*:\n",
    "      - Flop count ~ (2/3) * n * beta^2\n",
    "      - Storage (LU factors) ~ n * (2*beta + 1) nonzeros\n",
    "    These are crude UPPER bounds; actual costs can be lower if solver does pivoting and reordering.\n",
    "    \"\"\"\n",
    "    flops = (2/3) * n * (beta**2)\n",
    "    nnz_LU_upper = n * (2*beta + 1)\n",
    "    return int(flops), int(nnz_LU_upper)\n",
    "\n",
    "\n",
    "# --- Analyze A ---------------------------------------\n",
    "Nx, Nz, Lx, Lz = 100, 100, 100, 100\n",
    "p, *_ = getParam_Sonar(Nx, Nz, Lx, Lz, UseSparseMatrices=True)\n",
    "A_csr = to_csr(p[\"A\"])\n",
    "stats_A = sparsity_stats(A_csr, name=\"A\", show=True)\n",
    "\n",
    "flops_A, nnzLU_A = lu_band_cost_upper_bounds(stats_A[\"n\"], stats_A[\"beta\"])\n",
    "print(f\"[A] Banded-LU upper bounds (as-is ordering):\")\n",
    "print(f\"    ~ flops ≤ {flops_A:.3e}\")\n",
    "print(f\"    ~ nnz(LU) ≤ {nnzLU_A:.3e}  (vs nnz(A) = {stats_A['nnz']:,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_L_from_A(p):\n",
    "    \"\"\"Return L from block A = [[0, I],[c^2 L, -αI]]. If p['L'] exists, use it.\"\"\"\n",
    "    if 'L' in p:\n",
    "        return to_csr(p['L'])\n",
    "\n",
    "    A = to_csr(p['A'])\n",
    "    n2 = A.shape[0]\n",
    "    assert n2 % 2 == 0, \"A must be 2N x 2N\"\n",
    "    N = n2 // 2\n",
    "\n",
    "    # bottom-left block is c^2 * L  (same sparsity as L)\n",
    "    L_tilde = A[N:, :N]              # CSR slice → CSR\n",
    "    return L_tilde\n",
    "\n",
    "# --- Analyze L ---------------------------------------\n",
    "L_csr = extract_L_from_A(p)\n",
    "stats_L = sparsity_stats(L_csr, name=\"L\", show=True)\n",
    "\n",
    "r = min(L_csr.shape[0], Nz * 5)\n",
    "c = min(L_csr.shape[1], Nz * 5)\n",
    "L_sub = L_csr[:r, :c]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.spy(L_sub, markersize=.5)\n",
    "ax.set_xlabel(\"column\")\n",
    "ax.set_ylabel(\"row\")\n",
    "ax.set_title(f\"L sparsity (top-left {r}×{c}) — showing 5-point stencil\")\n",
    "ax.set_xlim(-0.5, c-0.5)\n",
    "ax.set_ylim(r-0.5, -0.5)  # keep origin at top-left visually\n",
    "ax.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import splu\n",
    "# grid sizes to test\n",
    "grids = [(10,10), (50,50), (100,100), (500,500)]\n",
    "Lx = Lz = 100.0  # physical sizes (use whatever you've been using)\n",
    "\n",
    "for Nx, Nz in grids:\n",
    "    try:\n",
    "        # build params and A (sparse)\n",
    "        p, *_ = getParam_Sonar(Nx, Nz, Lx, Lz, UseSparseMatrices=True)\n",
    "        A = p[\"A\"]\n",
    "        if not sp.issparse(A):\n",
    "            A = sp.csr_matrix(A)\n",
    "\n",
    "        # time LU factorization (SuperLU)\n",
    "        t0 = time.perf_counter()\n",
    "        lu = splu(A.tocsc(), permc_spec=\"COLAMD\", diag_pivot_thresh=1.0)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        print(f\"LU(A) Nx={Nx:4d}, Nz={Nz:4d} | n={A.shape[0]:,} | time = {t1 - t0:.3f} s\")\n",
    "    except MemoryError:\n",
    "        print(f\"LU(A) Nx={Nx:4d}, Nz={Nz:4d} | n≈{(2*Nx*Nz):,} | SKIPPED (MemoryError)\")\n",
    "    except Exception as e:\n",
    "        print(f\"LU(A) Nx={Nx:4d}, Nz={Nz:4d} | ERROR: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Runtime grows roughly with the grid size because, in our natural ordering, the half-bandwidth is set by Nz (β≈Nz), so a banded LU has work ~ O(n·β²).\n",
    "In practice, splu applies a fill-reducing ordering (e.g., COLAMD), which slashes effective bandwidth/fill so the observed scaling is closer to ~O(N^15) (e.g., quadrupling nodes → ~8× time).\n",
    "So: Nz controls the band, and splu's reordering is why the timings remain fast until you reach multi-million unknowns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### b) Estimate speed up if matrix were reordered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Comparing splu natrual which does no reordering to splu COLMAD which handles reordering as well as reverse_cuthill_mckee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import reverse_cuthill_mckee\n",
    "\n",
    "def to_csc(A): return A.tocsc() if sp.isspmatrix(A) else sp.csc_matrix(A)\n",
    "\n",
    "def factor_time(A_csc, permc):\n",
    "    t0 = time.perf_counter()\n",
    "    lu = splu(A_csc, permc_spec=permc, diag_pivot_thresh=1.0)\n",
    "    dt = time.perf_counter() - t0\n",
    "    fill = (lu.L.nnz + lu.U.nnz) / A_csc.nnz  # How many more nonzeros in LU vs A\n",
    "    return dt, fill\n",
    "\n",
    "def run_reordering_speedup(Nx, Nz, Lx=100.0, Lz=100.0):\n",
    "    p, *_ = getParam_Sonar(Nx, Nz, Lx, Lz, UseSparseMatrices=True)\n",
    "    A = p[\"A\"];  A = A if sp.issparse(A) else sp.csr_matrix(A)\n",
    "    A_csc = to_csc(A)\n",
    "\n",
    "    # 1) Baseline: NATURAL (no column reordering)\n",
    "    t_nat, fill_nat = factor_time(A_csc, \"NATURAL\")\n",
    "\n",
    "    # 2) SuperLU's fill-reducing ordering: COLAMD\n",
    "    t_colamd, fill_colamd = factor_time(A_csc, \"COLAMD\")\n",
    "\n",
    "    # 3) Variable reordering: RCM on the (symmetrized) pattern, then NATURAL\n",
    "    perm = reverse_cuthill_mckee((A != 0).astype(np.int8))\n",
    "    A_rcm = A[perm][:, perm]\n",
    "    t_rcm_nat, fill_rcm_nat = factor_time(to_csc(A_rcm), \"NATURAL\")\n",
    "\n",
    "    print(f\"Nx=Nz={Nx:4d} | n={A.shape[0]:,}\")\n",
    "    print(f\"  NATURAL    : time={t_nat:8.3f}s  fill={fill_nat:6.2f}x\")\n",
    "    print(f\"  COLAMD     : time={t_colamd:8.3f}s  fill={fill_colamd:6.2f}x  (speedup vs NATURAL ≈ {t_nat/max(t_colamd,1e-12):.1f}×)\")\n",
    "    print(f\"  RCM+NATURAL: time={t_rcm_nat:8.3f}s  fill={fill_rcm_nat:6.2f}x  (speedup vs NATURAL ≈ {t_nat/max(t_rcm_nat,1e-12):.1f}×)\")\n",
    "\n",
    "# Example sweep (keep sizes reasonable to avoid OOM):\n",
    "for n in [50, 100, 150, 200]:\n",
    "    run_reordering_speedup(n, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "In the natural ordering, the matrix's \"band\" is set by Nz, so elimination creates tons of new nonzeros (\"fill\"), making LU slow as the grid gets bigger. COLAMD (the default in splu) reorders the columns to reduce fill, so the factors are much sparser and the LU runs tens to hundreds of times faster. RCM (Reverse Cuthill–McKee) is a symmetric graph reordering that shrinks bandwidth; it helps, but not as much as COLAMD for our unsymmetric block system, so its speedups are smaller."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
