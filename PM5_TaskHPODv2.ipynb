{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PM5 – Task H: Model Order Reduction POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigs, splu\n",
    "from scipy.linalg import eig, solve, lu_factor, lu_solve\n",
    "import time\n",
    "\n",
    "# Import sonar simulation functions\n",
    "from getParam_Sonar import getParam_Sonar\n",
    "from eval_f_Sonar import eval_f_Sonar\n",
    "from eval_g_Sonar import eval_g_Sonar\n",
    "from eval_u_Sonar import eval_u_Sonar\n",
    "from simpleLeapFrog import LeapfrogSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FULL-ORDER MODEL SETUP\n",
    "# ============================================================\n",
    "\n",
    "# Grid size: 360×240 = 86,400 spatial points → 172,800 state variables\n",
    "# Higher resolution to support 1-6 kHz frequency sweep + harmonics\n",
    "Nx, Nz = 360, 240\n",
    "\n",
    "# Domain size: 45m×30m (90λ × 60λ at 3kHz)\n",
    "Lx, Lz = 45.0, 30.0\n",
    "\n",
    "print(f\"Setting up {Nx}×{Nz} grid over {Lx}m × {Lz}m domain\")\n",
    "print(f\"State dimension: 2N = {2*Nx*Nz}\")\n",
    "\n",
    "# Get parameters\n",
    "p, x_start, t_start, t_stop, max_dt_FE = getParam_Sonar(Nx, Nz, Lx, Lz, UseSparseMatrices=True)\n",
    "\n",
    "# Center the source (getParam_Sonar defaults to Nx//4)\n",
    "p['sonar_ix'] = Nx // 2\n",
    "N = Nx * Nz\n",
    "source_idx = p['sonar_ix'] * Nz + p['sonar_iz']\n",
    "B_lil = sp.lil_matrix((2*N, 1), dtype=float)\n",
    "B_lil[N + source_idx, 0] = 1.0 / (p['dx'] * p['dz'])\n",
    "p['B'] = B_lil.tocsr()\n",
    "\n",
    "# Two hydrophones: one co-located with source, one downstream\n",
    "hydro_1_x = Nx // 3  # First hydrophone (co-located with source at index 15 from Nx//4)\n",
    "hydro_2_x = 2* Nx // 3  # Second hydrophone (at index 30 from Nx//4)\n",
    "spacing = hydro_2_x - hydro_1_x  # Spacing between hydrophones\n",
    "\n",
    "# Override source to match first hydrophone\n",
    "p['sonar_ix'] = hydro_1_x\n",
    "source_idx = p['sonar_ix'] * Nz + p['sonar_iz']\n",
    "B_lil = sp.lil_matrix((2*N, 1), dtype=float)\n",
    "B_lil[N + source_idx, 0] = 1.0 / (p['dx'] * p['dz'])\n",
    "p['B'] = B_lil.tocsr()\n",
    "\n",
    "p['hydrophones'] = {\n",
    "    'z_pos': p['sonar_iz'],\n",
    "    'x_indices': [hydro_1_x, hydro_2_x],\n",
    "    'n_phones': 2\n",
    "}\n",
    "\n",
    "# Calculate separation distance\n",
    "separation_m = (hydro_2_x - hydro_1_x) * p['dx']\n",
    "\n",
    "print(f\"✓ Source at x-index {p['sonar_ix']} = {p['sonar_ix']*p['dx']:.1f}m\")\n",
    "print(f\"✓ Hydrophone 1 (co-located): x-index {hydro_1_x} = {hydro_1_x*p['dx']:.1f}m\")\n",
    "print(f\"✓ Hydrophone 2: x-index {hydro_2_x} = {hydro_2_x*p['dx']:.1f}m\")\n",
    "print(f\"✓ Separation: {separation_m:.2f}m → expected delay: {separation_m/1500*1e3:.1f} ms\")\n",
    "print(f\"✓ Max stable dt: {max_dt_FE:.6f}s\")\n",
    "\n",
    "# Verify Nyquist criterion for target frequency range\n",
    "print(f\"\\n=== NYQUIST VERIFICATION (1-6 kHz + harmonics) ===\")\n",
    "for f in [1000, 3000, 4000, 6000, 8000]:  # Test frequencies including 2× harmonic\n",
    "    wavelength = 1500 / f\n",
    "    ppw_x = wavelength / p['dx']\n",
    "    ppw_z = wavelength / p['dz']\n",
    "    status = \"✓\" if min(ppw_x, ppw_z) >= 2 else \"⚠️\" if min(ppw_x, ppw_z) >= 1 else \"✗\"\n",
    "    print(f\"{f:5d} Hz: λ={wavelength:.3f}m → {ppw_x:.1f}×{ppw_z:.1f} pts/λ {status}\")\n",
    "\n",
    "# Input: 3 kHz pulse with amplified amplitude\n",
    "\n",
    "# Note: B matrix already has 1/(dx*dz) scaling, so u(t) just needs amplitude\n",
    "amplitude_scale = 1e6  \n",
    "print(f\"Input amplitude: {amplitude_scale:.1e} × base pulse\")\n",
    "print(f\"\\nModel ready for POD analysis!\")\n",
    "\n",
    "def eval_u_scaled(t):\n",
    "    return amplitude_scale * eval_u_Sonar(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# REFERENCE SIMULATION WITH LEAPFROG SOLVER\n",
    "# ============================================================\n",
    "\n",
    "# Simulation parameters\n",
    "# Domain 45m×30m → ~30ms to cross → simulate for 40ms (includes reflections)\n",
    "t_sim = 0.04  # seconds (40 ms)\n",
    "dt = max_dt_FE * 0.5  # Half of max stable timestep for safety\n",
    "num_steps = int(np.ceil(t_sim / dt))\n",
    "\n",
    "print(f\"Running reference simulation...\")\n",
    "print(f\"  Duration: {t_sim*1000:.1f} ms\")\n",
    "print(f\"  Timestep: {dt*1e6:.2f} μs\")\n",
    "print(f\"  Number of steps: {num_steps}\")\n",
    "print(f\"  State dimension: {x_start.shape[0]}\")\n",
    "print(f\"\\nThis may take 30 sec - 1 min for 173k states...\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "X_ref, t_ref = LeapfrogSolver(\n",
    "    eval_f_Sonar, \n",
    "    x_start, \n",
    "    p, \n",
    "    eval_u_scaled, \n",
    "    num_steps, \n",
    "    dt, \n",
    "    visualize=False,\n",
    "    verbose=True\n",
    ")\n",
    "sim_time = time.perf_counter() - t0\n",
    "\n",
    "print(f\"\\n✓ Simulation complete in {sim_time:.2f}s\")\n",
    "print(f\"✓ State history: {X_ref.shape} ({X_ref.nbytes/1e6:.1f} MB)\")\n",
    "print(f\"✓ Time vector: {len(t_ref)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create animation of wave propagation\n",
    "import create_wave_animation as cwa\n",
    "\n",
    "print(\"Creating wave animation (this may take 30-60 seconds)...\")\n",
    "anim = cwa.create_wave_animation(X_ref, t_ref, p, save_filename='POD_reference_wave.gif')\n",
    "print(\"\\n✓ Animation saved as 'POD_reference_wave.gif'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hydrophone output y(t) = C*x(t) for all time steps\n",
    "print(\"Computing hydrophone responses...\")\n",
    "y_ref = np.zeros((2, len(t_ref)))  # 2 hydrophones × time samples\n",
    "\n",
    "for i in range(len(t_ref)):\n",
    "    y_ref[:, i] = eval_g_Sonar(X_ref[:, i], p).flatten()\n",
    "\n",
    "# Plot both hydrophone responses\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Hydrophone 1 (co-located with source)\n",
    "ax1.plot(t_ref * 1000, y_ref[0, :], 'b-', linewidth=1.5)\n",
    "ax1.set_ylabel('Pressure (Pa)', fontsize=11)\n",
    "ax1.set_title('Hydrophone 1: Co-located with Source', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)\n",
    "max_p1 = np.max(np.abs(y_ref[0, :]))\n",
    "ax1.text(0.02, 0.98, f'Peak: {max_p1:.2e} Pa', \n",
    "         transform=ax1.transAxes, fontsize=9, \n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "# Hydrophone 2 (downstream)\n",
    "ax2.plot(t_ref * 1000, y_ref[1, :], 'r-', linewidth=1.5)\n",
    "ax2.set_xlabel('Time (ms)', fontsize=12)\n",
    "ax2.set_ylabel('Pressure (Pa)', fontsize=11)\n",
    "ax2.set_title(f'Hydrophone 2: Downstream (Δx = {separation_m:.2f}m)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)\n",
    "max_p2 = np.max(np.abs(y_ref[1, :]))\n",
    "ax2.text(0.02, 0.98, f'Peak: {max_p2:.2e} Pa', \n",
    "         transform=ax2.transAxes, fontsize=9, \n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Hydrophone responses computed: {y_ref.shape[1]} samples × 2 hydrophones\")\n",
    "print(f\"✓ Hydrophone 1 peak: {max_p1:.3e} Pa\")\n",
    "print(f\"✓ Hydrophone 2 peak: {max_p2:.3e} Pa\")\n",
    "print(f\"✓ Expected delay: {separation_m/1500*1e3:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Multi-Frequency Snapshot Collection for POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MULTI-FREQUENCY SNAPSHOT COLLECTION\n",
    "# ============================================================\n",
    "import os\n",
    "\n",
    "# CONTROL FLAG: Set to False to skip simulation and load from saved data\n",
    "RUN_SNAPSHOT_COLLECTION = False\n",
    "\n",
    "frequencies_Hz = [1000, 2000, 3000, 4000, 5000, 6000]  # 1-6 kHz range\n",
    "snapshot_spacing = 1  # KEEP EVERY TIMESTEP - no subsampling for proper temporal dynamics!\n",
    "save_dir = \"PODsample_fullres\"\n",
    "\n",
    "# Helper functions for save/load\n",
    "def save_snapshots(X_pod, y_pod, frequencies, save_dir=\"PODsample_fullres\"):\n",
    "    \"\"\"Save snapshot matrices to disk for reuse.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    np.save(os.path.join(save_dir, \"X_pod.npy\"), X_pod)\n",
    "    np.save(os.path.join(save_dir, \"y_pod.npy\"), y_pod)\n",
    "    np.save(os.path.join(save_dir, \"frequencies.npy\"), np.array(frequencies))\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'shape_X': X_pod.shape,\n",
    "        'shape_y': y_pod.shape,\n",
    "        'frequencies': frequencies,\n",
    "        'grid': (Nx, Nz),\n",
    "        'domain': (Lx, Lz),\n",
    "        'snapshot_spacing': snapshot_spacing,\n",
    "        'dt': dt,\n",
    "        'num_steps': num_steps\n",
    "    }\n",
    "    np.save(os.path.join(save_dir, \"metadata.npy\"), metadata)\n",
    "    \n",
    "    print(f\"✓ Saved snapshots to '{save_dir}/' directory\")\n",
    "    print(f\"  - X_pod.npy: {X_pod.nbytes/1e6:.1f} MB\")\n",
    "    print(f\"  - y_pod.npy: {y_pod.nbytes/1e6:.1f} MB\")\n",
    "\n",
    "def load_snapshots(save_dir=\"PODsample_fullres\"):\n",
    "    \"\"\"Load previously saved snapshot matrices.\"\"\"\n",
    "    X_pod = np.load(os.path.join(save_dir, \"X_pod.npy\"))\n",
    "    y_pod = np.load(os.path.join(save_dir, \"y_pod.npy\"))\n",
    "    metadata = np.load(os.path.join(save_dir, \"metadata.npy\"), allow_pickle=True).item()\n",
    "    \n",
    "    print(f\"✓ Loaded snapshots from '{save_dir}/' directory\")\n",
    "    print(f\"  - X_pod: {X_pod.shape} ({X_pod.nbytes/1e6:.1f} MB)\")\n",
    "    print(f\"  - y_pod: {y_pod.shape} ({y_pod.nbytes/1e6:.1f} MB)\")\n",
    "    print(f\"  - Frequencies: {metadata['frequencies']} Hz\")\n",
    "    print(f\"  - Grid: {metadata['grid']}, Domain: {metadata['domain']} m\")\n",
    "    \n",
    "    return X_pod, y_pod, metadata\n",
    "\n",
    "# Main execution logic\n",
    "if RUN_SNAPSHOT_COLLECTION:\n",
    "    print(f\"Collecting FULL RESOLUTION snapshots from {len(frequencies_Hz)} frequency simulations...\")\n",
    "    print(f\"Frequencies: {frequencies_Hz} Hz\")\n",
    "    print(f\"⚠️  NO SUBSAMPLING - keeping all {num_steps+1} timesteps per frequency\\n\")\n",
    "\n",
    "    X_snapshots = []\n",
    "    y_snapshots = []\n",
    "    total_time = 0\n",
    "\n",
    "    for i, freq in enumerate(frequencies_Hz):\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"[{i+1}/{len(frequencies_Hz)}] Running {freq} Hz simulation...\")\n",
    "        \n",
    "        # Create input function for this frequency\n",
    "        # Gaussian envelope with ~3-5 cycles at current frequency\n",
    "        def eval_u_freq(t):\n",
    "            f0 = freq\n",
    "            A0 = amplitude_scale\n",
    "            n_cycles = 3\n",
    "            sigma = n_cycles / (2 * f0)  # Pulse width for n cycles\n",
    "            t0 = 3 * sigma  # Center pulse after 3 sigma\n",
    "            \n",
    "            envelope = np.exp(-(t - t0)**2 / (2 * sigma**2))\n",
    "            \n",
    "            # Only active within 4 sigma\n",
    "            if abs(t - t0) > 4 * sigma:\n",
    "                return 0.0\n",
    "            \n",
    "            return A0 * envelope * np.sin(2 * np.pi * f0 * t)\n",
    "        \n",
    "        # Run simulation\n",
    "        t0_sim = time.perf_counter()\n",
    "        X_freq, t_freq = LeapfrogSolver(\n",
    "            eval_f_Sonar, \n",
    "            x_start, \n",
    "            p, \n",
    "            eval_u_freq, \n",
    "            num_steps, \n",
    "            dt, \n",
    "            visualize=False, \n",
    "            verbose=False\n",
    "        )\n",
    "        sim_time = time.perf_counter() - t0_sim\n",
    "        total_time += sim_time\n",
    "        \n",
    "        # NO SUBSAMPLING - keep all timesteps\n",
    "        X_snapshots.append(X_freq)\n",
    "        \n",
    "        # Also collect hydrophone outputs for this frequency\n",
    "        y_freq = np.zeros((2, X_freq.shape[1]))\n",
    "        for j in range(X_freq.shape[1]):\n",
    "            y_freq[:, j] = eval_g_Sonar(X_freq[:, j], p).flatten()\n",
    "        y_snapshots.append(y_freq)\n",
    "        \n",
    "        print(f\"  ✓ Complete in {sim_time:.1f}s\")\n",
    "        print(f\"  ✓ Collected {X_freq.shape[1]} snapshots ({X_freq.nbytes/1e6:.1f} MB\")\n",
    "        print(f\"  ✓ Hydrophone peak: {np.max(np.abs(y_freq)):.2e} Pa\")\n",
    "\n",
    "    # Concatenate all snapshots horizontally\n",
    "    X_pod = np.hstack(X_snapshots)\n",
    "    y_pod = np.hstack(y_snapshots)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SNAPSHOT COLLECTION COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"✓ Total snapshots: {X_pod.shape[1]} ({len(frequencies_Hz)} frequencies × {num_steps+1} each)\")\n",
    "    print(f\"✓ Snapshot matrix: {X_pod.shape} ({X_pod.nbytes/1e6:.1f} MB)\")\n",
    "    print(f\"✓ Output matrix: {y_pod.shape} ({y_pod.nbytes/1e6:.1f} MB)\")\n",
    "    print(f\"✓ Total simulation time: {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
    "    \n",
    "    # Save snapshots for future use\n",
    "    save_snapshots(X_pod, y_pod, frequencies_Hz, save_dir)\n",
    "    \n",
    "    print(f\"\\n✓ Ready for SVD/POD analysis!\")\n",
    "\n",
    "else:\n",
    "    print(\"⊘ RUN_SNAPSHOT_COLLECTION = False\")\n",
    "    print(f\"Loading snapshots from '{save_dir}/' directory...\\n\")\n",
    "    \n",
    "    X_pod, y_pod, metadata = load_snapshots(save_dir)\n",
    "    \n",
    "    print(f\"\\n✓ Ready for SVD/POD analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD AND VISUALIZE SNAPSHOTS\n",
    "# ============================================================\n",
    "\n",
    "# Load the saved snapshots\n",
    "X_loaded, y_loaded, meta = load_snapshots(save_dir)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SNAPSHOT DATA STRUCTURE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"X_pod shape: {X_loaded.shape}\")\n",
    "print(f\"  - State dimension: {X_loaded.shape[0]} (should be 2×Nx×Nz = {2*Nx*Nz})\")\n",
    "print(f\"  - Total snapshots: {X_loaded.shape[1]}\")\n",
    "print(f\"  - Snapshots per frequency: ~{X_loaded.shape[1]//len(frequencies_Hz)}\")\n",
    "print(f\"\\ny_pod shape: {y_loaded.shape}\")\n",
    "print(f\"  - Hydrophones: {y_loaded.shape[0]}\")\n",
    "print(f\"  - Time samples: {y_loaded.shape[1]}\")\n",
    "print(f\"\\nMetadata:\")\n",
    "print(f\"  - Frequencies: {meta['frequencies']} Hz\")\n",
    "print(f\"  - Grid: {meta['grid']}\")\n",
    "print(f\"  - Domain: {meta['domain']} m\")\n",
    "print(f\"  - Snapshot spacing: every {meta['snapshot_spacing']}th timestep\")\n",
    "\n",
    "# Calculate snapshots per frequency (they should all be the same)\n",
    "n_snaps_per_freq = X_loaded.shape[1] // len(frequencies_Hz)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SNAPSHOT DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Since snapshots are concatenated, we need to figure out where each frequency starts/ends\n",
    "# They should be in order: [1kHz snapshots | 2kHz snapshots | ... | 6kHz snapshots]\n",
    "for i, freq in enumerate(frequencies_Hz):\n",
    "    start_idx = i * n_snaps_per_freq\n",
    "    end_idx = (i + 1) * n_snaps_per_freq if i < len(frequencies_Hz)-1 else X_loaded.shape[1]\n",
    "    \n",
    "    # Get snapshots for this frequency\n",
    "    X_freq_snaps = X_loaded[:, start_idx:end_idx]\n",
    "    y_freq_snaps = y_loaded[:, start_idx:end_idx]\n",
    "    \n",
    "    # Compute statistics\n",
    "    max_state = np.max(np.abs(X_freq_snaps))\n",
    "    max_pressure_h1 = np.max(np.abs(y_freq_snaps[0, :]))\n",
    "    max_pressure_h2 = np.max(np.abs(y_freq_snaps[1, :]))\n",
    "    \n",
    "    print(f\"{freq:4d} Hz: snapshots [{start_idx:4d}:{end_idx:4d}] = {end_idx-start_idx:3d} samples\")\n",
    "    print(f\"         Max |x|: {max_state:.2e}, Max |y1|: {max_pressure_h1:.2e}, Max |y2|: {max_pressure_h2:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOT HYDROPHONE RESPONSES FOR SELECTED FREQUENCIES\n",
    "# ============================================================\n",
    "\n",
    "# Plot 1, 3, and 6 kHz with separate columns for each hydrophone\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "\n",
    "# Reconstruct time vector (approximate since we subsampled)\n",
    "# Each simulation was t_sim = 40ms with dt ≈ 30μs\n",
    "# With snapshot_spacing = 10, effective dt_snapshot ≈ 300μs\n",
    "dt_snapshot = dt * snapshot_spacing\n",
    "n_snaps_per_freq = X_loaded.shape[1] // len(frequencies_Hz)\n",
    "t_snapshot = np.arange(n_snaps_per_freq) * dt_snapshot * 1000  # Convert to ms\n",
    "\n",
    "# Select frequencies to plot: 1, 3, 6 kHz (indices 0, 2, 5)\n",
    "freq_indices = [0, 2, 5]\n",
    "selected_freqs = [frequencies_Hz[i] for i in freq_indices]\n",
    "\n",
    "for plot_row, freq_idx in enumerate(freq_indices):\n",
    "    freq = frequencies_Hz[freq_idx]\n",
    "    \n",
    "    # Extract snapshots for this frequency\n",
    "    start_idx = freq_idx * n_snaps_per_freq\n",
    "    end_idx = (freq_idx + 1) * n_snaps_per_freq if freq_idx < len(frequencies_Hz)-1 else X_loaded.shape[1]\n",
    "    y_freq = y_loaded[:, start_idx:end_idx]\n",
    "    \n",
    "    # Left column: Hydrophone 1 (co-located with source)\n",
    "    ax_left = axes[plot_row, 0]\n",
    "    ax_left.plot(t_snapshot[:y_freq.shape[1]], y_freq[0, :], 'b-', linewidth=1.5)\n",
    "    ax_left.set_ylabel('Pressure (Pa)', fontsize=11)\n",
    "    ax_left.set_title(f'{freq} Hz - Hydrophone 1 (Source)', fontsize=12, fontweight='bold')\n",
    "    ax_left.grid(True, alpha=0.3)\n",
    "    ax_left.axhline(y=0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    max_p1 = np.max(np.abs(y_freq[0, :]))\n",
    "    ax_left.text(0.02, 0.98, f'Peak: {max_p1:.2e} Pa', \n",
    "                 transform=ax_left.transAxes, fontsize=9, \n",
    "                 verticalalignment='top', \n",
    "                 bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    if plot_row == 2:  # Bottom row\n",
    "        ax_left.set_xlabel('Time (ms)', fontsize=11)\n",
    "    \n",
    "    # Right column: Hydrophone 2 (downstream)\n",
    "    ax_right = axes[plot_row, 1]\n",
    "    ax_right.plot(t_snapshot[:y_freq.shape[1]], y_freq[1, :], 'r-', linewidth=1.5)\n",
    "    ax_right.set_ylabel('Pressure (Pa)', fontsize=11)\n",
    "    ax_right.set_title(f'{freq} Hz - Hydrophone 2 (Downstream)', fontsize=12, fontweight='bold')\n",
    "    ax_right.grid(True, alpha=0.3)\n",
    "    ax_right.axhline(y=0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    max_p2 = np.max(np.abs(y_freq[1, :]))\n",
    "    ax_right.text(0.02, 0.98, f'Peak: {max_p2:.2e} Pa', \n",
    "                  transform=ax_right.transAxes, fontsize=9, \n",
    "                  verticalalignment='top', \n",
    "                  bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
    "    \n",
    "    if plot_row == 2:  # Bottom row\n",
    "        ax_right.set_xlabel('Time (ms)', fontsize=11)\n",
    "    \n",
    "    # Print comparison\n",
    "    print(f\"{freq:4d} Hz - H1 peak: {max_p1:.2e} Pa, H2 peak: {max_p2:.2e} Pa, Ratio: {max_p2/max_p1:.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Hydrophone Responses: 1, 3, 6 kHz (Separation = {separation_m:.1f}m)', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.subplots_adjust(top=0.97)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Plotted hydrophone responses for {selected_freqs} Hz\")\n",
    "print(f\"✓ Time resolution: {dt_snapshot*1e6:.1f} μs between snapshots\")\n",
    "print(f\"✓ Duration per frequency: {t_snapshot[-1]:.1f} ms\")\n",
    "print(f\"✓ Expected delay between hydrophones: {separation_m/1500*1e3:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZE SPATIAL SNAPSHOTS (WAVE FIELDS)\n",
    "# ============================================================\n",
    "\n",
    "# Pick a few representative snapshots from each frequency to visualize\n",
    "# We'll show the pressure field (first half of state vector)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "# Snapshot times in ms: 2.5, 10, 25 ms\n",
    "snapshot_times_ms = [2.5, 10.0, 25.0]\n",
    "snapshot_times = [int(t_ms / (dt_snapshot * 1000)) for t_ms in snapshot_times_ms]  # Convert to indices\n",
    "\n",
    "for freq_idx in range(3):  # Show first 3 frequencies (1, 2, 3 kHz)\n",
    "    freq = frequencies_Hz[freq_idx]\n",
    "    \n",
    "    for snap_idx, t_idx in enumerate(snapshot_times):\n",
    "        ax = axes[freq_idx, snap_idx]\n",
    "        \n",
    "        # Get snapshot index in full array\n",
    "        start_idx = freq_idx * n_snaps_per_freq\n",
    "        global_idx = start_idx + t_idx\n",
    "        \n",
    "        # Extract pressure field (first N elements of state vector)\n",
    "        p_field = X_loaded[:N, global_idx].reshape(Nx, Nz)\n",
    "        \n",
    "        # Plot as 2D heatmap\n",
    "        im = ax.imshow(p_field.T, origin='lower', aspect='auto', \n",
    "                       extent=[0, Lx, 0, Lz], cmap='RdBu_r',\n",
    "                       vmin=-np.max(np.abs(p_field)), vmax=np.max(np.abs(p_field)))\n",
    "        \n",
    "        # Mark hydrophone locations\n",
    "        h1_x = hydro_1_x * p['dx']\n",
    "        h2_x = hydro_2_x * p['dx']\n",
    "        h_z = p['sonar_iz'] * p['dz']\n",
    "        ax.plot([h1_x], [h_z], 'go', markersize=8, markeredgecolor='k', markeredgewidth=1.5, label='H1')\n",
    "        ax.plot([h2_x], [h_z], 'mo', markersize=8, markeredgecolor='k', markeredgewidth=1.5, label='H2')\n",
    "        \n",
    "        time_ms = snapshot_times_ms[snap_idx]\n",
    "        ax.set_title(f'{freq} Hz @ t={time_ms:.1f}ms', fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('x (m)', fontsize=9)\n",
    "        \n",
    "        if snap_idx == 0:\n",
    "            ax.set_ylabel(f'{freq} Hz\\nz (m)', fontsize=9, fontweight='bold')\n",
    "        else:\n",
    "            ax.set_ylabel('z (m)', fontsize=9)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Pressure (Pa)', fontsize=8)\n",
    "        cbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Pressure Field Snapshots (POD Training Data)', \n",
    "             fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.subplots_adjust(top=0.97)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Visualized spatial snapshots for first 3 frequencies\")\n",
    "print(f\"✓ Showing snapshots at t = {snapshot_times_ms} ms\")\n",
    "print(f\"✓ Green marker = Hydrophone 1 (co-located with source)\")\n",
    "print(f\"✓ Magenta marker = Hydrophone 2 (downstream)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## SVD/POD Analysis\n",
    "\n",
    "**Note:** Assumes cells 9-11 have been run (loading snapshots and computing frequency distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostic:\n",
    "print(f\"X_loaded stats:\")\n",
    "print(f\"  Shape: {X_loaded.shape}\")\n",
    "print(f\"  Dtype: {X_loaded.dtype}\")\n",
    "print(f\"  Has NaN: {np.any(np.isnan(X_loaded))}\")\n",
    "print(f\"  Has Inf: {np.any(np.isinf(X_loaded))}\")\n",
    "print(f\"  Max: {np.max(np.abs(X_loaded)):.3e}\")\n",
    "print(f\"  Sample values: {X_loaded[:5, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PERFORM SVD ON SNAPSHOT MATRIX WITH PROPER PRESSURE-VELOCITY SCALING\n",
    "# ============================================================\n",
    "# Note: Assumes cells 9-12 have been run where we loaded X_loaded, y_loaded, \n",
    "# and computed n_snaps_per_freq for frequency distribution\n",
    "\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PERFORMING SVD WITH PHYSICAL SCALING\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"X_loaded shape: {X_loaded.shape}\")\n",
    "print(f\"  - State dimension: {X_loaded.shape[0]}\")\n",
    "print(f\"  - Number of snapshots: {X_loaded.shape[1]}\")\n",
    "print(f\"  - Matrix size: {X_loaded.shape[0] * X_loaded.shape[1]:,} elements ({X_loaded.nbytes/1e9:.2f} GB)\")\n",
    "print(f\"  - Data type: {X_loaded.dtype}\")\n",
    "\n",
    "# ============================================================\n",
    "# CRITICAL: Scale pressure and velocity to comparable magnitudes\n",
    "# ============================================================\n",
    "# The state vector x = [p; v] mixes pressure (Pa) and velocity (m/s)\n",
    "# These have vastly different magnitudes, which breaks POD basis quality\n",
    "# and causes the ROM projection to have unstable eigenvalues\n",
    "\n",
    "N = Nx * Nz  # Number of spatial points\n",
    "\n",
    "# Split snapshots into pressure and velocity components\n",
    "p_snapshots = X_loaded[:N, :]      # Pressure field (first N states)\n",
    "v_snapshots = X_loaded[N:, :]      # Velocity field (second N states)\n",
    "\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(\"COMPUTING SCALING FACTORS\")\n",
    "print(\"─\" * 80)\n",
    "\n",
    "# Compute characteristic scales using standard deviation (RMS-like measure)\n",
    "p_scale = np.std(p_snapshots)  # Characteristic pressure variation\n",
    "v_scale = np.std(v_snapshots)  # Characteristic velocity variation\n",
    "\n",
    "print(f\"Pressure component:\")\n",
    "print(f\"  - Mean: {np.mean(p_snapshots):.3e} Pa\")\n",
    "print(f\"  - Std:  {p_scale:.3e} Pa  ← scaling factor\")\n",
    "print(f\"  - Max:  {np.max(np.abs(p_snapshots)):.3e} Pa\")\n",
    "\n",
    "print(f\"\\nVelocity component:\")\n",
    "print(f\"  - Mean: {np.mean(v_snapshots):.3e} m/s\")\n",
    "print(f\"  - Std:  {v_scale:.3e} m/s  ← scaling factor\")\n",
    "print(f\"  - Max:  {np.max(np.abs(v_snapshots)):.3e} m/s\")\n",
    "\n",
    "print(f\"\\nMagnitude ratio: p_scale / v_scale = {p_scale/v_scale:.3e}\")\n",
    "print(f\"⚠️  Without scaling, POD would be dominated by {'pressure' if p_scale > v_scale else 'velocity'}!\")\n",
    "\n",
    "# Create scaled snapshot matrix\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(\"SCALING SNAPSHOTS TO UNIT VARIANCE\")\n",
    "print(\"─\" * 80)\n",
    "\n",
    "X_scaled = np.zeros_like(X_loaded)\n",
    "X_scaled[:N, :] = p_snapshots / p_scale   # Normalize pressure\n",
    "X_scaled[N:, :] = v_snapshots / v_scale   # Normalize velocity\n",
    "\n",
    "# Verify scaling worked\n",
    "print(f\"Scaled snapshot statistics:\")\n",
    "print(f\"  - Pressure part: mean={np.mean(X_scaled[:N, :]):.3e}, std={np.std(X_scaled[:N, :]):.3f} (target: ~1.0)\")\n",
    "print(f\"  - Velocity part: mean={np.mean(X_scaled[N:, :]):.3e}, std={np.std(X_scaled[N:, :]):.3f} (target: ~1.0)\")\n",
    "print(f\"✓ Both components now have comparable magnitudes!\")\n",
    "\n",
    "# ============================================================\n",
    "# PERFORM RANDOMIZED SVD ON SCALED DATA\n",
    "# ============================================================\n",
    "n_components = min(2000, X_scaled.shape[1])  # Can't have more components than snapshots\n",
    "\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(f\"RUNNING RANDOMIZED SVD ON SCALED SNAPSHOTS\")\n",
    "print(\"─\" * 80)\n",
    "print(f\"Computing first {n_components} singular values/vectors...\")\n",
    "print(f\"This will take 4-6 minutes...\\n\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "# Randomized SVD: much faster for large matrices, keeps first k components\n",
    "# U_scaled: spatial modes for SCALED data (172800 × n_components)\n",
    "# Sigma: singular values (n_components,)\n",
    "# VT: temporal coefficients (n_components × 16254)\n",
    "U_scaled, Sigma, VT = randomized_svd(\n",
    "    X_scaled,  # ← Using SCALED snapshots!\n",
    "    n_components=n_components,\n",
    "    n_iter=5,  # Number of power iterations (higher = more accurate)\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "svd_time = time.perf_counter() - t0\n",
    "\n",
    "print(f\"✓ Randomized SVD complete in {svd_time:.2f}s ({svd_time/60:.1f} min)\")\n",
    "\n",
    "# ============================================================\n",
    "# UN-SCALE POD MODES BACK TO PHYSICAL UNITS\n",
    "# ============================================================\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(\"RESTORING POD MODES TO PHYSICAL UNITS\")\n",
    "print(\"─\" * 80)\n",
    "\n",
    "# Create unscaled POD basis: multiply each component by its scale\n",
    "U = np.zeros_like(U_scaled)\n",
    "U[:N, :] = U_scaled[:N, :] * p_scale    # Pressure modes (Pa)\n",
    "U[N:, :] = U_scaled[N:, :] * v_scale    # Velocity modes (m/s)\n",
    "\n",
    "print(f\"Physical POD modes:\")\n",
    "print(f\"  - Pressure modes: min={np.min(U[:N, :]):.3e}, max={np.max(U[:N, :]):.3e} Pa\")\n",
    "print(f\"  - Velocity modes: min={np.min(U[N:, :]):.3e}, max={np.max(U[N:, :]):.3e} m/s\")\n",
    "print(f\"✓ POD basis restored to physical units!\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY SVD RESULTS\n",
    "# ============================================================\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(\"SVD VALIDATION\")\n",
    "print(\"─\" * 80)\n",
    "print(f\"  U shape: {U.shape} (spatial POD modes in physical units)\")\n",
    "print(f\"  Sigma shape: {Sigma.shape} (singular values)\")\n",
    "print(f\"  VT shape: {VT.shape} (temporal coefficients)\")\n",
    "\n",
    "print(f\"\\nSingular value validation:\")\n",
    "print(f\"  σ_max (σ[0]): {Sigma[0]:.3e}\")\n",
    "print(f\"  σ_min (σ[-1]): {Sigma[-1]:.3e}\")\n",
    "print(f\"  Condition number: {Sigma[0]/Sigma[-1]:.3e}\")\n",
    "print(f\"  σ[0] > σ[-1]: {Sigma[0] > Sigma[-1]}\")  # Should be True\n",
    "print(f\"  First 10 σ values: {Sigma[:10]}\")\n",
    "\n",
    "if Sigma[0] < Sigma[-1] or Sigma[0] < 1e-10:\n",
    "    print(\"\\n⚠️  ERROR: Singular values look incorrect!\")\n",
    "    print(\"Try increasing n_iter or check data scaling.\")\n",
    "else:\n",
    "    # Compute cumulative energy capture\n",
    "    energy = Sigma**2\n",
    "    total_energy = np.sum(energy)\n",
    "    cumulative_energy = np.cumsum(energy) / total_energy\n",
    "    \n",
    "    print(f\"\\n{'─'*80}\")\n",
    "    print(\"ENERGY DISTRIBUTION\")\n",
    "    print(\"─\" * 80)\n",
    "    print(f\"  Total energy (Σσ²): {total_energy:.3e}\")\n",
    "    print(f\"  Energy in first 100 modes: {cumulative_energy[99]*100:.2f}%\")\n",
    "    print(f\"  Energy in first 500 modes: {cumulative_energy[min(499, len(Sigma)-1)]*100:.2f}%\")\n",
    "    print(f\"  Energy in all {len(Sigma)} modes: {cumulative_energy[-1]*100:.2f}%\")\n",
    "    \n",
    "    # Find number of modes for various energy thresholds\n",
    "    thresholds = [0.90, 0.95, 0.99, 0.999, 0.9999]\n",
    "    print(f\"\\nModes needed for energy capture:\")\n",
    "    for thresh in thresholds:\n",
    "        n_modes = np.searchsorted(cumulative_energy, thresh) + 1\n",
    "        if n_modes <= len(Sigma):\n",
    "            print(f\"  {thresh*100:5.2f}% energy: q = {n_modes:4d} modes ({n_modes/len(Sigma)*100:.2f}% of total)\")\n",
    "        else:\n",
    "            print(f\"  {thresh*100:5.2f}% energy: > {len(Sigma)} modes (need more components)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"✓ SCALED SVD COMPLETE - POD BASIS READY FOR ROM CONSTRUCTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"The POD modes (U) are now in physical units and properly balanced.\")\n",
    "print(f\"Eigenvalues of ROM matrices should be much more stable!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DETECT ELBOW POINTS / DROPS IN SINGULAR VALUE SPECTRUM\n",
    "# ============================================================\n",
    "\n",
    "# Bin singular values into groups of 10 and compute average drop per bin\n",
    "bin_size = 25\n",
    "n_bins = len(Sigma) // bin_size\n",
    "\n",
    "# Compute relative drop across each bin: (σ_bin_start - σ_bin_end) / σ_bin_start\n",
    "bin_drops = np.zeros(n_bins)\n",
    "bin_start_modes = np.zeros(n_bins, dtype=int)\n",
    "\n",
    "for i in range(n_bins):\n",
    "    start_idx = i * bin_size\n",
    "    end_idx = (i + 1) * bin_size - 1\n",
    "    \n",
    "    bin_start_modes[i] = start_idx + 1  # 1-based mode number at start of bin\n",
    "    \n",
    "    # Relative drop from start to end of bin\n",
    "    bin_drops[i] = (Sigma[start_idx] - Sigma[end_idx]) / Sigma[start_idx]\n",
    "\n",
    "# Find top 10 bins with largest relative drops\n",
    "top_n_bins = 10\n",
    "top_bin_indices = np.argsort(bin_drops)[::-1][:top_n_bins]\n",
    "drop_mode_bins = bin_start_modes[top_bin_indices]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ELBOW POINT DETECTION: Top 10 Largest Relative Drops (10-mode bins)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<6} {'Mode Range':<18} {'σ_start':<15} {'σ_end':<15} {'Rel. Drop':<12} {'Energy %'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank, bin_idx in enumerate(top_bin_indices, 1):\n",
    "    start_mode = bin_start_modes[bin_idx]\n",
    "    end_mode = start_mode + bin_size - 1\n",
    "    \n",
    "    start_idx = (bin_idx) * bin_size\n",
    "    end_idx = start_idx + bin_size - 1\n",
    "    \n",
    "    sigma_start = Sigma[start_idx]\n",
    "    sigma_end = Sigma[end_idx]\n",
    "    rel_drop = bin_drops[bin_idx]\n",
    "    energy_pct = cumulative_energy[end_idx] * 100\n",
    "    \n",
    "    print(f\"{rank:<6} {start_mode:4d} - {end_mode:<9d} {sigma_start:<15.3e} {sigma_end:<15.3e} {rel_drop:<12.4f} {energy_pct:>6.2f}%\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================\n",
    "# PLOT SINGULAR VALUES WITH ELBOW POINTS MARKED\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Singular values on semi-log scale with elbow points\n",
    "ax1 = axes[0]\n",
    "ax1.semilogy(range(1, len(Sigma) + 1), Sigma, 'b-', linewidth=2, marker='o', \n",
    "             markersize=4, markevery=max(1, len(Sigma)//50), label='Singular values')\n",
    "ax1.set_xlabel('Mode Number (i)', fontsize=12)\n",
    "ax1.set_ylabel('Singular Value σ_i', fontsize=12)\n",
    "ax1.set_title('Singular Value Spectrum with Elbow Bins', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, which='both')\n",
    "ax1.set_xlim(0, len(Sigma))\n",
    "\n",
    "# Mark top 5 elbow bins on the plot\n",
    "colors = ['red', 'orange', 'gold', 'yellow', 'lightgreen']\n",
    "for rank in range(min(5, len(drop_mode_bins))):\n",
    "    start_mode = drop_mode_bins[rank]\n",
    "    end_mode = start_mode + bin_size - 1\n",
    "    \n",
    "    # Highlight the bin range\n",
    "    start_idx = start_mode - 1\n",
    "    end_idx = end_mode - 1\n",
    "    \n",
    "    # Shade the bin region\n",
    "    ax1.axvspan(start_mode, end_mode, alpha=0.2, color=colors[rank], \n",
    "                label=f'Elbow #{rank+1}: modes {start_mode}-{end_mode}')\n",
    "    \n",
    "    # Mark start and end points\n",
    "    ax1.plot(start_mode, Sigma[start_idx], 'o', color=colors[rank], markersize=10, \n",
    "             markeredgecolor='k', markeredgewidth=1.5, zorder=10)\n",
    "    ax1.plot(end_mode, Sigma[end_idx], 's', color=colors[rank], markersize=8, \n",
    "             markeredgecolor='k', markeredgewidth=1.5, zorder=10)\n",
    "    \n",
    "    # Add annotation\n",
    "    mid_mode = (start_mode + end_mode) // 2\n",
    "    mid_idx = mid_mode - 1\n",
    "    ax1.annotate(f'{start_mode}-{end_mode}', \n",
    "                xy=(mid_mode, Sigma[mid_idx]), \n",
    "                xytext=(mid_mode + len(Sigma)*0.05, Sigma[mid_idx]*0.5),\n",
    "                fontsize=9, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor=colors[rank], alpha=0.7),\n",
    "                arrowprops=dict(arrowstyle='->', color='k', lw=1.5))\n",
    "\n",
    "ax1.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Right plot: Cumulative energy capture with elbow points\n",
    "ax2 = axes[1]\n",
    "ax2.plot(range(1, len(Sigma) + 1), cumulative_energy * 100, 'r-', linewidth=2)\n",
    "ax2.set_xlabel('Number of Modes (q)', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Energy Captured (%)', fontsize=12)\n",
    "ax2.set_title('Energy Capture vs Number of POD Modes', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(0, min(750, len(Sigma)))  # Extended to 750 modes\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "# Add horizontal lines for common thresholds with different colored markers\n",
    "threshold_colors = {'90': 'green', '95': 'blue', '99': 'purple', '99.9': 'red'}\n",
    "threshold_markers = []\n",
    "\n",
    "for thresh in [90, 95, 99, 99.9]:\n",
    "    ax2.axhline(y=thresh, color='k', linestyle='--', linewidth=1, alpha=0.4)\n",
    "    n_modes = np.searchsorted(cumulative_energy, thresh/100) + 1\n",
    "    \n",
    "    # Get the singular value at this threshold\n",
    "    if n_modes <= len(Sigma):\n",
    "        sigma_at_thresh = Sigma[n_modes - 1]\n",
    "        \n",
    "        # Position label on right side\n",
    "        ax2.text(min(750, len(Sigma))*0.98, thresh, f'{thresh}%', \n",
    "                fontsize=9, ha='right', va='bottom')\n",
    "        \n",
    "        # Mark the point where this threshold is reached with different color\n",
    "        if n_modes <= min(750, len(Sigma)):\n",
    "            color = threshold_colors[str(thresh)]\n",
    "            marker = ax2.plot(n_modes, thresh, 'o', markersize=8, color=color, \n",
    "                            markeredgecolor='k', markeredgewidth=1.5, zorder=10,\n",
    "                            label=f'{thresh}%: q={n_modes}, σ={sigma_at_thresh:.2e}')[0]\n",
    "            threshold_markers.append(marker)\n",
    "\n",
    "# Add legend for threshold markers in bottom right\n",
    "if threshold_markers:\n",
    "    ax2.legend(loc='lower right', fontsize=8, framealpha=0.9)\n",
    "\n",
    "# Mark elbow points on energy plot (if within x-range)\n",
    "for rank in range(min(5, len(drop_mode_bins))):\n",
    "    start_mode = drop_mode_bins[rank]\n",
    "    end_mode = start_mode + bin_size - 1\n",
    "    \n",
    "    if start_mode <= min(750, len(Sigma)):\n",
    "        # Shade the bin region on energy plot\n",
    "        if end_mode <= min(750, len(Sigma)):\n",
    "            ax2.axvspan(start_mode, end_mode, alpha=0.2, color=colors[rank])\n",
    "        else:\n",
    "            ax2.axvspan(start_mode, min(750, len(Sigma)), alpha=0.2, color=colors[rank])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Plotted singular value spectrum and energy capture\")\n",
    "print(f\"✓ Total modes available: {len(Sigma)}\")\n",
    "print(f\"✓ Detected {len(drop_mode_bins)} elbow bins using {bin_size}-mode binning\")\n",
    "print(f\"✓ Top 5 suggested truncation bins: {[f'{drop_mode_bins[i]}-{drop_mode_bins[i]+bin_size-1}' for i in range(min(5, len(drop_mode_bins)))]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Creating Reduced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD REDUCED-ORDER MODELS (ROMs) AT SELECTED TRUNCATION POINTS\n",
    "# ============================================================\n",
    "\n",
    "# Selection criteria based on elbow detection and energy analysis:\n",
    "# \n",
    "# Energy thresholds (from randomized SVD results):\n",
    "#   - 90% energy: q = 250 modes (12.50% of available modes)\n",
    "#   - 95% energy: q = 279 modes (13.95% of available modes)\n",
    "#   - 99% energy: q = 319 modes (15.95% of available modes)\n",
    "#   - 99.9% energy: q = 350 modes (17.50% of available modes)\n",
    "#\n",
    "# Elbow points (major drops in singular value spectrum):\n",
    "#   - Elbow #1: modes 351-375 (rel. drop 0.7642) - after 99.9% energy\n",
    "#   - Elbow #2: modes 376-400 (rel. drop 0.9154) - large drop\n",
    "#   - Elbow #3: modes 451-475 (rel. drop 0.9998) - MASSIVE drop → noise floor\n",
    "#\n",
    "# Selected truncation points for ROM comparison:\n",
    "#   q = 400:  Just after major elbow at 376-400\n",
    "#             → Captures all physically meaningful dynamics before noise\n",
    "#   \n",
    "#   q = 500:  Well past the massive drop at 451-475\n",
    "#             → Tests if modes beyond main elbow improve accuracy\n",
    "#   \n",
    "#   q = 1475: Near end of available modes (before numerical noise dominates)\n",
    "#             → Upper bound to verify no useful information in high modes\n",
    "\n",
    "truncation_points = [100, 200, 300, 400, 500]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BUILDING REDUCED-ORDER MODELS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Full-order model dimension: N = {X_loaded.shape[0]}\")\n",
    "print(f\"Total available POD modes: {len(Sigma)}\")\n",
    "print(f\"\\nSelected truncation points: {truncation_points}\")\n",
    "print(f\"Compression ratios: {[f'{q}/{X_loaded.shape[0]} = {q/X_loaded.shape[0]*100:.2f}%' for q in truncation_points]}\")\n",
    "\n",
    "# Store ROMs in a dictionary for easy access\n",
    "ROMs = {}\n",
    "\n",
    "for q in truncation_points:\n",
    "    print(f\"\\n{'─'*80}\")\n",
    "    print(f\"Building ROM with q = {q} modes...\")\n",
    "    \n",
    "    # Extract first q POD modes (spatial basis)\n",
    "    U_q = U[:, :q]\n",
    "    \n",
    "    # Project system matrices onto reduced basis\n",
    "    # Reduced state: x̃ ∈ ℝ^q, where x ≈ U_q @ x̃\n",
    "    # Reduced dynamics: dx̃/dt = Ã*x̃ + B̃*u, where Ã = U_q^T * A * U_q, B̃ = U_q^T * B\n",
    "    # Reduced output: y = C̃*x̃, where C̃ = C * U_q\n",
    "    \n",
    "    # For our system, we need to work with A, B, C from parameter dict\n",
    "    A = p['A']  # System matrix (sparse)\n",
    "    B = p['B']  # Input matrix (sparse)\n",
    "    \n",
    "    # Compute reduced matrices\n",
    "    print(f\"  Computing Ã = U_q^T @ A @ U_q ...\")\n",
    "    A_reduced = U_q.T @ (A @ U_q)  # Result is dense q×q matrix\n",
    "    \n",
    "    print(f\"  Computing B̃ = U_q^T @ B ...\")\n",
    "    B_reduced = U_q.T @ B.toarray()  # Convert sparse to dense for projection\n",
    "    \n",
    "    # For output matrix C, we need to extract hydrophone measurements\n",
    "    # C is implicitly defined in eval_g_Sonar, but for ROM we need C * U_q\n",
    "    # We'll compute this by evaluating C on each column of U_q\n",
    "    print(f\"  Computing C̃ = C @ U_q ...\")\n",
    "    n_outputs = p['hydrophones']['n_phones']\n",
    "    C_reduced = np.zeros((n_outputs, q))\n",
    "    \n",
    "    for i in range(q):\n",
    "        # Evaluate output for i-th POD mode\n",
    "        C_reduced[:, i] = eval_g_Sonar(U_q[:, i], p).flatten()\n",
    "    \n",
    "    # Store ROM components\n",
    "    ROMs[q] = {\n",
    "        'q': q,\n",
    "        'U_q': U_q,\n",
    "        'A_reduced': A_reduced,\n",
    "        'B_reduced': B_reduced,\n",
    "        'C_reduced': C_reduced,\n",
    "        'energy_captured': cumulative_energy[q-1] * 100,\n",
    "        'compression_ratio': q / X_loaded.shape[0]\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ ROM built successfully\")\n",
    "    print(f\"    - State dimension: {X_loaded.shape[0]} → {q} ({q/X_loaded.shape[0]*100:.2f}%)\")\n",
    "    print(f\"    - Energy captured: {cumulative_energy[q-1]*100:.2f}%\")\n",
    "    print(f\"    - Matrix sizes: Ã {A_reduced.shape}, B̃ {B_reduced.shape}, C̃ {C_reduced.shape}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ All {len(ROMs)} reduced-order models created successfully!\")\n",
    "print(f\"✓ ROM dictionary keys: {list(ROMs.keys())}\")\n",
    "print(f\"\\nReady to test ROM accuracy against full-order reference simulation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RUN REDUCED-ORDER MODEL SIMULATIONS WITH LEAPFROG SOLVER\n",
    "# ============================================================\n",
    "\n",
    "# We'll simulate each ROM using the same Leapfrog solver as the reference\n",
    "# This ensures consistent numerical behavior and stability\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RUNNING REDUCED-ORDER MODEL SIMULATIONS (LEAPFROG)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Reference simulation (full-order):\")\n",
    "print(f\"  - State dimension: {X_loaded.shape[0]}\")\n",
    "print(f\"  - Simulation time: {sim_time:.2f}s (from cell 4)\")\n",
    "print(f\"  - Duration: {t_sim*1000:.1f} ms, dt: {dt*1e6:.2f} μs, steps: {num_steps}\")\n",
    "\n",
    "# Verify input signal is 3 kHz pulse\n",
    "print(f\"\\nInput signal verification:\")\n",
    "print(f\"  - eval_u_scaled(0.0001) = {eval_u_scaled(0.0001):.3e} (3 kHz Gaussian pulse)\")\n",
    "print(f\"  - eval_u_scaled(0.001) = {eval_u_scaled(0.001):.3e}\")\n",
    "print(f\"  - eval_u_scaled(0.01) = {eval_u_scaled(0.01):.3e}\")\n",
    "\n",
    "# Store ROM simulation results\n",
    "ROM_results = {}\n",
    "\n",
    "for q in truncation_points:\n",
    "    print(f\"\\n{'─'*80}\")\n",
    "    print(f\"Running ROM with q = {q} modes...\")\n",
    "    print(f\"  Compression: {X_loaded.shape[0]} → {q} ({q/X_loaded.shape[0]*100:.2f}%)\")\n",
    "    \n",
    "    # Get ROM components\n",
    "    rom = ROMs[q]\n",
    "    A_r = rom['A_reduced']\n",
    "    B_r = rom['B_reduced']\n",
    "    C_r = rom['C_reduced']\n",
    "    U_q = rom['U_q']\n",
    "    \n",
    "    # Initial condition in reduced space: x̃_0 = U_q^T @ x_0\n",
    "    x0_reduced = (U_q.T @ x_start).flatten()\n",
    "    \n",
    "    # Diagnostic: Check ROM matrix properties\n",
    "    print(f\"  ROM matrix diagnostics:\")\n",
    "    print(f\"    - Ã shape: {A_r.shape}, dtype: {A_r.dtype}\")\n",
    "    print(f\"    - Ã max: {np.max(np.abs(A_r)):.3e}, has NaN: {np.any(np.isnan(A_r))}, has Inf: {np.any(np.isinf(A_r))}\")\n",
    "    print(f\"    - B̃ shape: {B_r.shape}, max: {np.max(np.abs(B_r)):.3e}\")\n",
    "    print(f\"    - C̃ shape: {C_r.shape}, max: {np.max(np.abs(C_r)):.3e}\")\n",
    "    print(f\"    - x̃_0 shape: {x0_reduced.shape}, max: {np.max(np.abs(x0_reduced)):.3e}\")\n",
    "    \n",
    "    # Check eigenvalues of A_reduced for stability (optional - can be slow for large q)\n",
    "    if q <= 500:\n",
    "        eigvals = np.linalg.eigvals(A_r)\n",
    "        max_real_eigval = np.max(np.real(eigvals))\n",
    "        print(f\"    - max(Re(λ)) = {max_real_eigval:.3e} (should be ≤ 0 for stability)\")\n",
    "        if max_real_eigval > 0:\n",
    "            print(f\"    ⚠️  WARNING: Positive eigenvalue detected - ROM may be unstable!\")\n",
    "    \n",
    "    # Create reduced eval_f function for this ROM\n",
    "    # The Leapfrog solver expects: f(x, p, u) where x is a column vector\n",
    "    def eval_f_reduced(x_reduced, p_unused, u):\n",
    "        \"\"\"\n",
    "        Reduced dynamics: dx̃/dt = Ã·x̃ + B̃·u\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x_reduced : array [q, 1] or [q,]\n",
    "            Reduced state vector\n",
    "        p_unused : dict\n",
    "            Not used for ROM (matrices already projected)\n",
    "        u : float\n",
    "            Input value at current time\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dxdt : array [q, 1]\n",
    "            Time derivative of reduced state\n",
    "        \"\"\"\n",
    "        x_vec = np.asarray(x_reduced).reshape(-1)  # Ensure 1D\n",
    "        \n",
    "        # Compute: Ã·x̃ + B̃·u\n",
    "        dxdt = A_r @ x_vec + (B_r * u).flatten()\n",
    "        \n",
    "        return dxdt.reshape(-1, 1)  # Return as column vector\n",
    "    \n",
    "    print(f\"  Running Leapfrog solver for {num_steps} time steps...\")\n",
    "    \n",
    "    # Test eval_f_reduced with initial condition and zero input\n",
    "    test_f = eval_f_reduced(x0_reduced.reshape(-1, 1), {}, 0.0)\n",
    "    print(f\"  Test eval_f_reduced(x̃_0, u=0): shape={test_f.shape}, max={np.max(np.abs(test_f)):.3e}\")\n",
    "    \n",
    "    # Run Leapfrog solver on reduced system\n",
    "    t0_rom = time.perf_counter()\n",
    "    \n",
    "    X_reduced, t_reduced = LeapfrogSolver(\n",
    "        eval_f_reduced,\n",
    "        x0_reduced.reshape(-1, 1),  # Initial state as column vector\n",
    "        {},  # Empty dict since we don't need p for ROM\n",
    "        eval_u_scaled,\n",
    "        num_steps,\n",
    "        dt,\n",
    "        visualize=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    rom_time = time.perf_counter() - t0_rom\n",
    "    \n",
    "    # Compute outputs: y = C̃·x̃ for all time steps\n",
    "    print(f\"  Computing hydrophone outputs...\")\n",
    "    print(f\"    - X_reduced shape: {X_reduced.shape} (expected: [{q}, {num_steps + 1}])\")\n",
    "    print(f\"    - ROM output represents: reduced state coefficients (NOT spatial field)\")\n",
    "    print(f\"    - To reconstruct full field: x_full = U_q @ x_reduced\")\n",
    "    \n",
    "    y_reduced = np.zeros((2, num_steps + 1))\n",
    "    for i in range(num_steps + 1):\n",
    "        y_reduced[:, i] = (C_r @ X_reduced[:, i]).flatten()\n",
    "    \n",
    "    print(f\"    - y_reduced shape: {y_reduced.shape} (expected: [2, {num_steps + 1}])\")\n",
    "    print(f\"    - y_reduced represents: hydrophone pressure outputs (2 sensors × time)\")\n",
    "    \n",
    "    # Store results\n",
    "    ROM_results[q] = {\n",
    "        'X_reduced': X_reduced,          # Reduced state history (q × num_steps+1)\n",
    "        'y_reduced': y_reduced,          # Hydrophone outputs (2 × num_steps+1)\n",
    "        't_vector': t_reduced,           # Time vector (same as reference)\n",
    "        'sim_time': rom_time,            # Computational time\n",
    "        'speedup': sim_time / rom_time,  # Speedup vs full-order\n",
    "        'energy': rom['energy_captured'],\n",
    "        'compression': rom['compression_ratio']\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ Simulation complete in {rom_time:.3f}s\")\n",
    "    print(f\"  ✓ Speedup vs full-order: {sim_time/rom_time:.2f}×\")\n",
    "    \n",
    "    # COMPREHENSIVE NUMERICAL DIAGNOSTICS\n",
    "    print(f\"\\n  Numerical validation:\")\n",
    "    \n",
    "    # Check reduced state\n",
    "    has_nan_X = np.any(np.isnan(X_reduced))\n",
    "    has_inf_X = np.any(np.isinf(X_reduced))\n",
    "    max_X = np.max(np.abs(X_reduced))\n",
    "    \n",
    "    print(f\"    X_reduced (state): max={max_X:.3e}, NaN={has_nan_X}, Inf={has_inf_X}\")\n",
    "    \n",
    "    if has_nan_X or has_inf_X:\n",
    "        # Find when instability occurred\n",
    "        for i in range(num_steps + 1):\n",
    "            if np.any(np.isnan(X_reduced[:, i])) or np.any(np.isinf(X_reduced[:, i])):\n",
    "                print(f\"    ⚠️  INSTABILITY at timestep {i}/{num_steps} (t={t_reduced[i]*1000:.3f} ms)\")\n",
    "                if i > 0:\n",
    "                    print(f\"        Previous max: {np.max(np.abs(X_reduced[:, i-1])):.3e}\")\n",
    "                print(f\"        Current max: {np.max(np.abs(X_reduced[:, i])):.3e}\")\n",
    "                break\n",
    "    \n",
    "    # Check output\n",
    "    has_nan_y = np.any(np.isnan(y_reduced))\n",
    "    has_inf_y = np.any(np.isinf(y_reduced))\n",
    "    max_y1 = np.max(np.abs(y_reduced[0, :]))\n",
    "    max_y2 = np.max(np.abs(y_reduced[1, :]))\n",
    "    \n",
    "    print(f\"    y_reduced (output): H1_max={max_y1:.3e}, H2_max={max_y2:.3e}\")\n",
    "    print(f\"                        NaN={has_nan_y}, Inf={has_inf_y}\")\n",
    "    \n",
    "    # Overall status\n",
    "    if has_nan_X or has_inf_X or has_nan_y or has_inf_y:\n",
    "        print(f\"  ❌ ROM q={q} FAILED - NaN/Inf detected\")\n",
    "    else:\n",
    "        print(f\"  ✓ ROM q={q} STABLE - All values finite\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SIMULATION TIMING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<15} {'q':<8} {'Time (s)':<12} {'Speedup':<10} {'Compression':<12} {'Status'}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Full-order':<15} {X_loaded.shape[0]:<8} {sim_time:<12.3f} {'1.00×':<10} {'100.00%':<12} {'✓ Stable'}\")\n",
    "for q in truncation_points:\n",
    "    res = ROM_results[q]\n",
    "    status = \"✓ Stable\" if not (np.any(np.isnan(res['X_reduced'])) or np.any(np.isinf(res['X_reduced']))) else \"❌ NaN/Inf\"\n",
    "    print(f\"{'ROM-' + str(q):<15} {q:<8} {res['sim_time']:<12.3f} {res['speedup']:<10.2f}× {res['compression']*100:>6.2f}%{' ':<6} {status}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ROM STABILITY SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "stable_roms = []\n",
    "unstable_roms = []\n",
    "for q in truncation_points:\n",
    "    res = ROM_results[q]\n",
    "    if np.any(np.isnan(res['X_reduced'])) or np.any(np.isinf(res['X_reduced'])):\n",
    "        unstable_roms.append(q)\n",
    "    else:\n",
    "        stable_roms.append(q)\n",
    "\n",
    "if stable_roms:\n",
    "    print(f\"✓ Stable ROMs (q): {stable_roms}\")\n",
    "if unstable_roms:\n",
    "    print(f\"❌ Unstable ROMs (q): {unstable_roms}\")\n",
    "    print(f\"\\nPossible causes of instability:\")\n",
    "    print(f\"  1. ROM projection error (Ã matrix may not preserve stability of A)\")\n",
    "    print(f\"  2. Timestep too large for reduced dynamics\")\n",
    "    print(f\"  3. Loss of dissipation in Galerkin projection\")\n",
    "    print(f\"  4. Numerical errors in SVD basis (check condition number)\")\n",
    "else:\n",
    "    print(f\"✓ All ROMs stable!\")\n",
    "\n",
    "print(f\"\\n✓ All ROM simulations complete!\")\n",
    "print(f\"✓ Results stored in ROM_results dictionary\")\n",
    "print(f\"\\nReady for error analysis and comparison...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Summary of POD-Based ROM Investigation\n",
    "\n",
    "## What We've Done\n",
    "\n",
    "### 1. **Multi-Frequency Snapshot Collection**\n",
    "- Collected snapshots from 6 frequency simulations (1-6 kHz)\n",
    "- Full temporal resolution (no subsampling): 16,254 snapshots total\n",
    "- State dimension: 172,800 (360×240 grid, pressure + velocity)\n",
    "- Total data: ~2.7 GB snapshot matrix\n",
    "\n",
    "### 2. **SVD/POD Analysis with Physical Scaling**\n",
    "- **Attempt 1 (Unscaled)**: Standard SVD on raw snapshots\n",
    "  - Pressure dominated (10^4 Pa vs 10^-2 m/s velocity)\n",
    "  - ROMs showed moderate instability (q=400, 500 stable but growing; q=1475 failed)\n",
    "  \n",
    "- **Attempt 2 (Std-Dev Scaling)**: Normalized pressure and velocity to unit variance\n",
    "  - Both components balanced (std ≈ 1.0 each)\n",
    "  - **Result: WORSE instability** - all ROMs now unstable\n",
    "  - Eigenvalues became larger, indicating fundamental Galerkin projection issue\n",
    "  \n",
    "### 3. **ROM Construction & Testing**\n",
    "- Built ROMs with q = [100, 200, 300, 400, 500] modes\n",
    "- Tested with Leapfrog time integration (same as full-order model)\n",
    "- Compression: 0.06% - 0.29% of full state dimension\n",
    "\n",
    "### 4. **Key Findings**\n",
    "\n",
    "#### ❌ **Critical Problem Identified:**\n",
    "The Galerkin projection `Ã = U^T @ A @ U` does **not preserve the stability structure** of the original wave equation system matrix `A`.\n",
    "\n",
    "**Evidence:**\n",
    "- Full-order model: Stable for 40ms simulation\n",
    "- ROM eigenvalues: **Positive real parts** → exponential growth\n",
    "  - Before scaling: max(Re(λ)) ≈ 10^2 to 10^3\n",
    "  - After scaling: max(Re(λ)) **increased** → worse instability\n",
    "- All ROMs eventually blow up (NaN/Inf) or show unphysical exponential growth\n",
    "\n",
    "#### 🔍 **Root Cause:**\n",
    "The wave equation system should have:\n",
    "- **Skew-symmetric** or **Hamiltonian** structure for energy conservation\n",
    "- Eigenvalues: purely imaginary (undamped) or ≤ 0 (damped)\n",
    "\n",
    "The POD basis from SVD is **energy-optimal** but **not structure-preserving**:\n",
    "- Doesn't respect pressure-velocity coupling\n",
    "- Breaks symplectic geometry of wave equations\n",
    "- Galerkin projection introduces artificial instability\n",
    "\n",
    "#### 📊 **What Worked:**\n",
    "- ✅ Snapshot collection pipeline\n",
    "- ✅ SVD computation (6 minutes, 2000 modes)\n",
    "- ✅ Energy analysis (90% at q=250, 99% at q=319)\n",
    "- ✅ ROM construction mechanics\n",
    "\n",
    "#### 📊 **What Failed:**\n",
    "- ❌ ROM stability (all truncation levels unstable)\n",
    "- ❌ Std-dev scaling (made it worse by exposing full instability)\n",
    "- ❌ Galerkin projection on non-structure-preserving discretization\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps (Prioritized)\n",
    "\n",
    "### 🔧 **Immediate Actions (Tomorrow)**\n",
    "\n",
    "#### 1. **Reduce Snapshot Matrix Size** ⚠️ **CRITICAL**\n",
    "**Current issue:** 172,800 × 16,254 matrix is too large for reliable numerical operations\n",
    "\n",
    "**Action:**\n",
    "```python\n",
    "# In cell 8 (snapshot collection):\n",
    "snapshot_spacing = 10  # Subsample by 10× (was 1)\n",
    "# This reduces to ~1,625 snapshots while keeping 6 frequencies\n",
    "# New size: 172,800 × 1,625 ≈ 280 MB (manageable)\n",
    "```\n",
    "\n",
    "**Justification:**\n",
    "- Nyquist: Need 2 samples per period\n",
    "- Highest freq = 6 kHz → period = 167 μs\n",
    "- Current dt = 14.77 μs → already 11× oversampled\n",
    "- Subsampling by 10× still gives 1.1× Nyquist margin ✓\n",
    "\n",
    "**Re-run:** Cells 8 → 9 → 14 (new SVD, ~3-4 min instead of 6 min)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Try Energy-Weighted POD** ⭐ **MOST PROMISING**\n",
    "**Theory:** Use physics-based inner product that preserves wave equation energy\n",
    "\n",
    "**Implementation:**\n",
    "```python\n",
    "# In cell 14, replace std-dev scaling with energy weighting:\n",
    "c = 1500.0  # Sound speed\n",
    "rho = 1000.0  # Water density\n",
    "\n",
    "# Energy metric weights\n",
    "w_p = 1.0 / (rho * c**2)  # Pressure: 1/(ρc²) ≈ 4.44e-10\n",
    "w_v = 1.0                 # Velocity: kinetic energy weight\n",
    "\n",
    "# Apply sqrt of weights (for inner product norm)\n",
    "X_weighted = np.zeros_like(X_loaded)\n",
    "X_weighted[:N, :] = p_snapshots * np.sqrt(w_p)\n",
    "X_weighted[N:, :] = v_snapshots * np.sqrt(w_v)\n",
    "\n",
    "# SVD on weighted data\n",
    "U_weighted, Sigma, VT = randomized_svd(X_weighted, ...)\n",
    "\n",
    "# Un-weight modes\n",
    "U[:N, :] = U_weighted[:N, :] / np.sqrt(w_p)\n",
    "U[N:, :] = U_weighted[N:, :] / np.sqrt(w_v)\n",
    "```\n",
    "\n",
    "**Expected result:** Eigenvalues close to zero or negative (stable ROM)\n",
    "\n",
    "**Time:** 15 min to implement + 4 min SVD = ~20 min\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Verify Leapfrog Stability for ROMs**\n",
    "**Check:** ROM timestep may need to be smaller than full-order\n",
    "\n",
    "**Test:**\n",
    "```python\n",
    "# In cell 18, add:\n",
    "dt_rom = dt * 0.1  # 10× smaller timestep for ROM\n",
    "num_steps_rom = int(np.ceil(t_sim / dt_rom))\n",
    "```\n",
    "\n",
    "**Diagnostic:** If this fixes instability → problem is timestep-dependent stiffness\n",
    "\n",
    "---\n",
    "\n",
    "### 🔬 **If Energy-Weighted POD Fails**\n",
    "\n",
    "#### 4. **Modal Damping Stabilization** (Engineering Fix)\n",
    "Add artificial damping to ROM matrices:\n",
    "\n",
    "```python\n",
    "# In cell 17 (ROM construction), after computing A_reduced:\n",
    "damping_ratio = 0.01  # 1% critical damping\n",
    "\n",
    "# Estimate modal frequencies from eigenvalues\n",
    "eigvals = np.linalg.eigvals(A_reduced)\n",
    "\n",
    "# Add damping: shift eigenvalues left in complex plane\n",
    "A_stabilized = A_reduced.copy()\n",
    "for i in range(q):\n",
    "    A_stabilized[i, i] -= damping_ratio * np.abs(eigvals[i])\n",
    "```\n",
    "\n",
    "**Pros:** Guaranteed stability\n",
    "**Cons:** Non-physical dissipation, may overdamp wave propagation\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Switch to Eigenvalue-Based ROM** (Alternative Approach)\n",
    "Bypass POD entirely, use eigenmodes of system matrix `A`\n",
    "\n",
    "**Method:**\n",
    "```python\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "# Compute first q eigenmodes of A (takes 10-30 min)\n",
    "eigvals, eigvecs = eigs(p['A'], k=q, which='SM')  # Smallest magnitude\n",
    "\n",
    "# Use eigenvectors as ROM basis (automatically stable!)\n",
    "U_eigen = eigvecs\n",
    "\n",
    "# Reduced A is diagonal: Ã = diag(λ_1, ..., λ_q)\n",
    "A_reduced = np.diag(eigvals)\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ✅ Guaranteed stable (only keep Re(λ) ≤ 0 modes)\n",
    "- ✅ No projection error in dynamics matrix\n",
    "- ✅ Works well for linear wave equations\n",
    "\n",
    "**Cons:**\n",
    "- ❌ Expensive eigenvalue computation (10-30 min)\n",
    "- ❌ Eigenmodes may not capture input-output behavior well\n",
    "- ❌ Complex arithmetic (wave modes are complex conjugate pairs)\n",
    "\n",
    "---\n",
    "\n",
    "### 📋 **Execution Plan for Tomorrow**\n",
    "\n",
    "**Phase 1: Data Reduction (30 min)**\n",
    "1. Set `snapshot_spacing = 10` in cell 8\n",
    "2. Re-run cells 8, 9 (load snapshots)\n",
    "3. Verify new size: ~1,625 snapshots\n",
    "\n",
    "**Phase 2: Energy-Weighted POD (20 min)**\n",
    "4. Implement energy weighting in cell 14\n",
    "5. Run SVD (~4 min)\n",
    "6. Check singular value spectrum\n",
    "\n",
    "**Phase 3: ROM Testing (10 min)**\n",
    "7. Re-run cells 17-18 (ROM construction + simulation)\n",
    "8. Check eigenvalues: are they ≤ 0 now?\n",
    "9. Check for NaN/Inf in results\n",
    "\n",
    "**Phase 4: Diagnosis (if still unstable)**\n",
    "10. Try smaller ROM timestep (dt × 0.1)\n",
    "11. If that works → stiffness issue\n",
    "12. If not → add modal damping OR switch to eigen-ROM\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "```\n",
    "Start: Reduced snapshots (spacing=10)\n",
    "  ↓\n",
    "Try: Energy-weighted POD\n",
    "  ↓\n",
    "Check: max(Re(λ)) of ROM eigenvalues\n",
    "  ↓\n",
    "  ├─ ≤ 0 → SUCCESS! Proceed with ROM analysis\n",
    "  │\n",
    "  ├─ > 0 but small → Try smaller timestep (dt × 0.1)\n",
    "  │   ↓\n",
    "  │   ├─ Stable → Use smaller dt for ROMs\n",
    "  │   └─ Unstable → Add modal damping (Option 4)\n",
    "  │\n",
    "  └─ >> 0 (large positive) → Galerkin fundamentally broken\n",
    "      ↓\n",
    "      Switch to eigenvalue-based ROM (Option 5)\n",
    "      OR accept limited accuracy and use damping\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Open Questions\n",
    "\n",
    "1. **Why is the full-order model stable but ROM isn't?**\n",
    "   - Likely: The spatial discretization has hidden dissipation that POD removes\n",
    "   - Or: The discretization is only *weakly* stable, and Galerkin amplifies errors\n",
    "\n",
    "2. **Is the snapshot data quality sufficient?**\n",
    "   - 6 frequencies may not span the full dynamics\n",
    "   - Could try: Add 7-10 kHz frequencies, or random chirps\n",
    "\n",
    "3. **Should we abandon POD-Galerkin for this problem?**\n",
    "   - Not yet - energy-weighted POD is the proper physics-based approach\n",
    "   - If that fails, then yes, eigenvalue ROM is more robust for wave equations\n",
    "\n",
    "---\n",
    "\n",
    "## References for Further Investigation\n",
    "\n",
    "- **Structure-preserving MOR:** Mehrmann & Stykel (2005) - Balanced truncation for second-order systems\n",
    "- **Symplectic POD:** Peng & Mohseni (2016) - Hamiltonian preserving POD\n",
    "- **Wave equation ROMs:** Bui-Thanh et al. (2008) - Model reduction for wave propagation\n",
    "- **Energy-stable ROM:** Carlberg et al. (2017) - Galerkin projection with energy preservation\n",
    "\n",
    "---\n",
    "\n",
    "**Status:** ⚠️ POD-Galerkin ROM is unstable due to non-structure-preserving projection. Energy-weighted POD is next attempt. If that fails, switch to eigenvalue-based ROM for guaranteed stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
